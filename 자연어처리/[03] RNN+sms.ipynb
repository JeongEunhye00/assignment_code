{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec904b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. pip 21.0 will drop support for Python 2.7 in January 2021. More details about Python 2 support in pip can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support pip 21.0 will remove support for this functionality.\u001b[0m\n",
      "Collecting torchtext==0.4.0\n",
      "  Downloading torchtext-0.4.0.tar.gz (45 kB)\n",
      "\u001b[K     |████████████████████████████████| 45 kB 4.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages (from torchtext==0.4.0) (4.36.1)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages (from torchtext==0.4.0) (2.26.0)\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages (from torchtext==0.4.0) (1.4.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages (from torchtext==0.4.0) (1.16.5)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages (from torchtext==0.4.0) (1.12.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages (from requests->torchtext==0.4.0) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages (from requests->torchtext==0.4.0) (2019.11.28)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2; python_version < \"3\" in /home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages (from requests->torchtext==0.4.0) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5; python_version < \"3\" in /home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages (from requests->torchtext==0.4.0) (2.8)\n",
      "Building wheels for collected packages: torchtext\n",
      "  Building wheel for torchtext (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for torchtext: filename=torchtext-0.4.0-py2-none-any.whl size=52129 sha256=761bf560878ebf302df68f2f55cec660bcf4bf5e1b67ad6ffd321c3168d324d0\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/86/a4/48/71e4abb43905ead16e32e61df3ca5f1da5e4d8c863d0008884\n",
      "Successfully built torchtext\n",
      "Installing collected packages: torchtext\n",
      "Successfully installed torchtext-0.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext==0.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2725d9",
   "metadata": {},
   "source": [
    "# [데이터 전처리]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5724f3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 256 # sms(메시지) 최대 길이"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719576c0",
   "metadata": {},
   "source": [
    "## 1. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb2488b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc7d7c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'label', u'sms'], dtype='object')\n",
      "(5572, 2)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('sms.tsv', sep='\\t', )\n",
    "print(df.columns)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "956d0bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                sms\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b467fbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of classes: 2\n",
      "['ham', 'spam']\n",
      "{'ham': 0, 'spam': 1}\n"
     ]
    }
   ],
   "source": [
    "# 클래스 파악\n",
    "classes = sorted(set(df['label']))\n",
    "class_to_idx = {}\n",
    "\n",
    "for i, c in enumerate(classes): # 모든 클래스에 대해\n",
    "    class_to_idx.update({c: i})\n",
    "    \n",
    "nclass = len(classes)\n",
    "\n",
    "print(\"# of classes: %d\" %nclass)\n",
    "print(classes)\n",
    "print(class_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b6aefb",
   "metadata": {},
   "source": [
    "## 2. 새로운 DataFrame\n",
    "\n",
    "### 1) 'label, sms' 만 남기기\n",
    "\n",
    "### 2) 최대 텍스트 길이 만큼 자르기 # pandas.Series.str.slice\n",
    "\n",
    "* '성별, 가사'만 남기려면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc783724",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame({'label': df['label'],\n",
    "                       'sms': df['sms'].str.slice( # 최대 가사 텍스트 만큼 자르기\n",
    "                           start=0, stop=max_length)\n",
    "                      })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc85e134",
   "metadata": {},
   "source": [
    "### 3) 중복 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61dc2d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cd85fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(new_df.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "442cdfac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5169"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce6fb9c",
   "metadata": {},
   "source": [
    "### 4) 셔플"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eddc0833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok. I asked for money how far</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Depends on individual lor e hair dresser say p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hmm... Dunno leh, mayb a bag 4 goigng out dat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>December only! Had your mobile 11mths+? You ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Spoons it is then okay?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                sms\n",
       "0   ham                      Ok. I asked for money how far\n",
       "1   ham  Depends on individual lor e hair dresser say p...\n",
       "2   ham  Hmm... Dunno leh, mayb a bag 4 goigng out dat ...\n",
       "3  spam  December only! Had your mobile 11mths+? You ar...\n",
       "4   ham                            Spoons it is then okay?"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shuffled = new_df.sample(frac=1).reset_index(drop=True)\n",
    "df_shuffled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77c5511",
   "metadata": {},
   "source": [
    "### 5) train, test 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06dba47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index for train: 0~4652\n",
      "index for test: 4652~5168\n"
     ]
    }
   ],
   "source": [
    "# train : test = 9 : 1\n",
    "# train : test = 540 : 60 -> train : valid : test = 432 : 108 : 60\n",
    "train_ratio = 0.9\n",
    "\n",
    "# train dataset\n",
    "s, e = 0, int(df_shuffled.shape[0] * train_ratio) # # of rows\n",
    "df_train = pd.DataFrame({'label': df_shuffled['label'][s:e],\n",
    "                         'sms': df_shuffled['sms'][s:e]})\n",
    "print(\"index for train: %d~%d\" %(s,e))\n",
    "\n",
    "# test dataset\n",
    "s, e = e, e+int(df_shuffled.shape[0]*(1.0-train_ratio))\n",
    "print(\"index for test: %d~%d\" %(s,e))\n",
    "df_test = pd.DataFrame({'label': df_shuffled['label'][s:e],\n",
    "                        'sms': df_shuffled['sms'][s:e]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f88e4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4652, 2)\n",
      "(516, 2)\n"
     ]
    }
   ],
   "source": [
    "# column 수 확인\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67a8585",
   "metadata": {},
   "source": [
    "### 6) 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98ca7815",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/OpenSSL/crypto.py:12: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in the next release.\n",
      "  from cryptography import x509\n"
     ]
    }
   ],
   "source": [
    "# new_df.columns : ['label', 'sms']\n",
    "df_train.to_csv('./sms.maxlen.uniq.shuf.train.tsv',\n",
    "                header=False, index=False, sep='\\t')\n",
    "df_test.to_csv('./sms.maxlen.uniq.shuf.test.tsv',\n",
    "                header=False, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd30bb6",
   "metadata": {},
   "source": [
    "# [데이터 로더]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c5618f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb56ecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced3fa9a",
   "metadata": {},
   "source": [
    "# [RNN + SMS 구현]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be4691a",
   "metadata": {},
   "source": [
    "## 0.1. 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b3f9dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ffef19",
   "metadata": {},
   "source": [
    "## 0.2. 하이퍼파라미터 셋팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa322575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "batch_size = 128\n",
    "num_epochs = 10\n",
    "\n",
    "word_vec_size = 256\n",
    "dropout_p = 0.3\n",
    "\n",
    "hidden_size = 512\n",
    "num_layers = 4\n",
    "\n",
    "## yhk 추가\n",
    "learning_rate = 0.001 # 디폴트 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f2d29fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3edbaf",
   "metadata": {},
   "source": [
    "## 1. SMS train, test dataset 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "571c9498",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6012aca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = DataLoader(\n",
    "    train_fn = './sms.maxlen.uniq.shuf.train.tsv',\n",
    "    batch_size=batch_size,\n",
    "    valid_ratio=.2,\n",
    "    device=-1,\n",
    "    max_vocab=999999,\n",
    "    min_freq=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08a397aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loaders = DataLoader(\n",
    "    train_fn = './sms.maxlen.uniq.shuf.test.tsv',\n",
    "    batch_size=batch_size,\n",
    "    valid_ratio=.01,\n",
    "    device=-1,\n",
    "    max_vocab=999999,\n",
    "    min_freq=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884a9862",
   "metadata": {},
   "source": [
    "## 2. 대략적인 데이터 형태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03129377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('|train| =', 3722, '|valid| =', 930)\n",
      "('|vocab| =', 1566, '|classes| =', 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"|train| =\", len(loaders.train_loader.dataset),\n",
    "      \"|valid| =\", len(loaders.valid_loader.dataset))\n",
    "\n",
    "vocab_size = len(loaders.text.vocab)\n",
    "num_classes = len(loaders.label.vocab)\n",
    "print('|vocab| =', vocab_size, \"|classes| =\", num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313322e0",
   "metadata": {},
   "source": [
    "## 3. 데이터 로드함수\n",
    "\n",
    "학습시킬 때 batch_size 단위로 끊어서 로드하기 위함\n",
    "\n",
    "### 데이터 로드함수 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e22a3902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "('\\xed\\x95\\x9c \\xeb\\xb2\\x88\\xec\\x97\\x90 \\xeb\\xa1\\x9c\\xeb\\x93\\x9c\\xeb\\x90\\x98\\xeb\\x8a\\x94 \\xeb\\x8d\\xb0\\xec\\x9d\\xb4\\xed\\x84\\xb0 \\xed\\x81\\xac\\xea\\xb8\\xb0:', 128)\n",
      "('label: ', array(0))\n",
      "('text: ', (6,))\n",
      "('label: ', array(0))\n",
      "('text: ', (6,))\n",
      "('label: ', array(0))\n",
      "('text: ', (6,))\n",
      "[1]\n",
      "('\\xed\\x95\\x9c \\xeb\\xb2\\x88\\xec\\x97\\x90 \\xeb\\xa1\\x9c\\xeb\\x93\\x9c\\xeb\\x90\\x98\\xeb\\x8a\\x94 \\xeb\\x8d\\xb0\\xec\\x9d\\xb4\\xed\\x84\\xb0 \\xed\\x81\\xac\\xea\\xb8\\xb0:', 128)\n",
      "('label: ', array(0))\n",
      "('text: ', (10,))\n",
      "('label: ', array(0))\n",
      "('text: ', (10,))\n",
      "('label: ', array(0))\n",
      "('text: ', (10,))\n",
      "[2]\n",
      "('\\xed\\x95\\x9c \\xeb\\xb2\\x88\\xec\\x97\\x90 \\xeb\\xa1\\x9c\\xeb\\x93\\x9c\\xeb\\x90\\x98\\xeb\\x8a\\x94 \\xeb\\x8d\\xb0\\xec\\x9d\\xb4\\xed\\x84\\xb0 \\xed\\x81\\xac\\xea\\xb8\\xb0:', 128)\n",
      "('label: ', array(0))\n",
      "('text: ', (6,))\n",
      "('label: ', array(0))\n",
      "('text: ', (6,))\n",
      "('label: ', array(0))\n",
      "('text: ', (6,))\n",
      "[3]\n",
      "('\\xed\\x95\\x9c \\xeb\\xb2\\x88\\xec\\x97\\x90 \\xeb\\xa1\\x9c\\xeb\\x93\\x9c\\xeb\\x90\\x98\\xeb\\x8a\\x94 \\xeb\\x8d\\xb0\\xec\\x9d\\xb4\\xed\\x84\\xb0 \\xed\\x81\\xac\\xea\\xb8\\xb0:', 128)\n",
      "('label: ', array(0))\n",
      "('text: ', (7,))\n",
      "('label: ', array(0))\n",
      "('text: ', (7,))\n",
      "('label: ', array(0))\n",
      "('text: ', (7,))\n"
     ]
    }
   ],
   "source": [
    "n = 3 # 샘플로 출력할 데이터 개수\n",
    "for i, data in enumerate(loaders.train_loader):\n",
    "    labels = data.label\n",
    "    texts = data.text\n",
    "    \n",
    "    if i>n:\n",
    "        break\n",
    "    print(\"[%d]\" %i)\n",
    "    print(\"한 번에 로드되는 데이터 크기:\", len(labels))\n",
    "    \n",
    "    # 출력\n",
    "    for j in range(n):\n",
    "        label = labels[j].numpy() # tensor -> numpy 로 변환\n",
    "        text = texts[j].numpy()\n",
    "        print(\"label: \", label)\n",
    "        print(\"text: \", text.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8f5b93",
   "metadata": {},
   "source": [
    "## 4. 모델 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3b87bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recurrent neural network (many-to-one)\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                input_size, # vocab_size\n",
    "                word_vec_size, # word embedding vector 차원\n",
    "                hidden_size, # bidirectional LSTM의 hidden state & cell state의 size\n",
    "                n_classes,\n",
    "                num_layers=4, # 쌓을 레이어 개수\n",
    "                dropout_p=0.3\n",
    "                ):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.word_vec_size = word_vec_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_classes = n_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        \n",
    "        # 입력 차원(vocab_size), 출력 차원(word_vec_size)\n",
    "        self.emb = nn.Embedding(input_size, word_vec_size) # 부터!\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=word_vec_size,\n",
    "                           hidden_size=hidden_size,\n",
    "                           num_layers=num_layers,\n",
    "                           dropout=dropout_p, # 얼만큼 끌지. 디폴트 0\n",
    "                           batch_first=True,\n",
    "                           bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size*2, num_classes)\n",
    "        # LogSoftmax + NLLoss instead of Softmax + CrossEntropy\n",
    "        self.activation = nn.LogSoftmax(dim=-1) # 마지막 차원에 softmax 씌워줌\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, length)\n",
    "        x = self.emb(x)\n",
    "        \n",
    "        # x: (batch_size, length, word_vec_size)\n",
    "        x, _ = self.lstm(x) # x: output, _ : 마지막 time step의 hidden state & cell state\n",
    "        \n",
    "        # x: (batch_size, length, hidden_size * 2)\n",
    "        # x[:,-1]: (batch_size, 1, hidden_size * 2)\n",
    "        out = self.activation(self.fc(x[:, -1])) # 마지막 time step\n",
    "        # self.fc(x[:, -1]): (batch_size, num_classes)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94337545",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_size=vocab_size,\n",
    "           word_vec_size=word_vec_size,\n",
    "           hidden_size=hidden_size,\n",
    "           n_classes=num_classes,\n",
    "           num_layers=num_layers, \n",
    "           dropout_p=dropout_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8426bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeAccr(dloader, model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    model.eval() # test mode\n",
    "    for i, data in enumerate(dloader): # batch_size 만큼\n",
    "        texts = data.text.to(device) # (batch_size, length)\n",
    "        labels = data.label.to(device) # (batch_size, num_classes)\n",
    "        \n",
    "        # Forward prop.\n",
    "        output = model(texts) # (batch_size, num_classes)\n",
    "        _, output_index = torch.max(output, 1) # (batch_size, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (output_index == labels).sum().float()\n",
    "    #print(\"Accuracy of Test Data: {}\".format(100*correct/total))\n",
    "    \n",
    "    model.train()\n",
    "    return (100*correct/total).numpy() # tensor -> numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7e33cdbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test Data: 12.26\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Test Data: %.2f\" %ComputeAccr(loaders.valid_loader, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ab4e37",
   "metadata": {},
   "source": [
    "## 5. loss, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "441e0e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "#loss_func = nn.CrossEntropyLoss()\n",
    "loss_func = nn.NLLLoss()\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11317611",
   "metadata": {},
   "source": [
    "## 6. 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5a2afbef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch [1/10, Step [10/30]], Loss: 0.3267, Accr: 87.74\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch [1/10, Step [20/30]], Loss: 0.2681, Accr: 87.74\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch [1/10, Step [30/30]], Loss: 0.5796, Accr: 87.74\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch [2/10, Step [10/30]], Loss: 1.6687, Accr: 87.74\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch [2/10, Step [20/30]], Loss: 0.2947, Accr: 87.74\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch [2/10, Step [30/30]], Loss: 0.1988, Accr: 88.06\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch [3/10, Step [10/30]], Loss: 1.0689, Accr: 87.74\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch [3/10, Step [20/30]], Loss: 0.5250, Accr: 87.96\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch [3/10, Step [30/30]], Loss: 0.1276, Accr: 87.74\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch [4/10, Step [10/30]], Loss: 0.2397, Accr: 89.57\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch [4/10, Step [20/30]], Loss: 0.1970, Accr: 91.94\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch [4/10, Step [30/30]], Loss: 0.4665, Accr: 92.69\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch [5/10, Step [10/30]], Loss: 0.1780, Accr: 88.82\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch [5/10, Step [20/30]], Loss: 0.7500, Accr: 92.37\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch [5/10, Step [30/30]], Loss: 0.3735, Accr: 94.09\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch [6/10, Step [10/30]], Loss: 0.0688, Accr: 95.91\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch [6/10, Step [20/30]], Loss: 0.0299, Accr: 92.04\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch [6/10, Step [30/30]], Loss: 0.0942, Accr: 93.44\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch [7/10, Step [10/30]], Loss: 0.2745, Accr: 94.73\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch [7/10, Step [20/30]], Loss: 0.2172, Accr: 94.41\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch [7/10, Step [30/30]], Loss: 0.0750, Accr: 95.70\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch [8/10, Step [10/30]], Loss: 0.0092, Accr: 95.91\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch [8/10, Step [20/30]], Loss: 0.1374, Accr: 96.34\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch [8/10, Step [30/30]], Loss: 0.2793, Accr: 95.38\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch [9/10, Step [10/30]], Loss: 0.1114, Accr: 94.09\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch [9/10, Step [20/30]], Loss: 0.0240, Accr: 95.59\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch [9/10, Step [30/30]], Loss: 0.0590, Accr: 96.45\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch [10/10, Step [10/30]], Loss: 0.0206, Accr: 96.88\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch [10/10, Step [20/30]], Loss: 0.0672, Accr: 96.34\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch [10/10, Step [30/30]], Loss: 0.0880, Accr: 96.99\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "total_step = len(loaders.train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(loaders.train_loader):\n",
    "        texts = data.text.to(device) # (batch_size, length)\n",
    "        labels = data.label.to(device) # (batch_size, num_classes)\n",
    "        \n",
    "        print(\"[%d]\" %i)\n",
    "        \n",
    "        # Forward prop.\n",
    "        outputs = model(texts)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        \n",
    "        # Backward prop. & optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 10 == 0:\n",
    "            print('Epoch [{}/{}, Step [{}/{}]], Loss: {:.4f}, Accr: {:.2f}'\n",
    "                 .format(epoch+1, num_epochs, i+1, total_step, loss.item(), ComputeAccr(loaders.valid_loader, model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7715c4e2",
   "metadata": {},
   "source": [
    "## 7. 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "245db36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Valid Data: 96.99\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Valid Data: %.2f\" %ComputeAccr(loaders.valid_loader, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bcd018",
   "metadata": {},
   "source": [
    "## 8. 학습된 파라미터 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2e097b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type RNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "netname = './nets/rnn_weight.pkl'\n",
    "torch.save(model, netname, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e736659",
   "metadata": {},
   "source": [
    "## 9. 학습된 파라미터 로드\n",
    "\n",
    "실무에서 학습된(pretrained) 파라미터 로드하고 싶다면: 5,6,8 과정 생략한 채 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1cbe7458",
   "metadata": {},
   "outputs": [],
   "source": [
    "netname = './nets/rnn_weight.pkl'\n",
    "model = torch.load(netname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f37231bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Valid Data: 96.99\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Valid Data: %.2f\" %ComputeAccr(loaders.valid_loader, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc0c617",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p27",
   "language": "python",
   "name": "conda_pytorch_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
